# ğŸ“Š Logistic Regression

This lecture covers **Logistic Regression**, a supervised learning algorithm used for **binary classification problems**.

---

## ğŸ¥ Lecture Recording
ğŸ‘‰ [Click here to watch the lecture](https://drive.google.com/file/d/1PZzmQiyEvCjxSl1JrITLksa6GFIS2exP/view?usp=sharing)

---

## ğŸ“‘ Slides
ğŸ‘‰ [Click here to view slides](https://clear-canvas-slides.lovable.app)

---

## ğŸ“Œ What You Will Learn

- Difference between linear and logistic regression
- Binary classification concept
- Sigmoid (logistic) function
- Decision boundary
- Understanding weights and bias
- Log loss (binary cross-entropy)
- Gradient descent for logistic regression
- Practical implementation using sklearn

---

## ğŸ§  Theory Overview

Logistic Regression follows the equation:

y = 1 / (1 + e^-(wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + b))

Where:
- **xâ‚, xâ‚‚** â†’ input features
- **wâ‚, wâ‚‚** â†’ weights
- **b** â†’ bias term
- **y** â†’ predicted probability

---

## ğŸ›  Tools & Libraries Used

- Python
- NumPy
- Pandas
- scikit-learn
